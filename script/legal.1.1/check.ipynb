{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\Thesis\\rerun\\wor2vec\\fold_0\\vocab_200.json\",'r') as f:\n",
    "    fi=json.load(f) \n",
    "newf=open('dict_200.pkl','wb')\n",
    "pickle.dump(fi,newf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from han.han import WordAttn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36663485, 0.94865797, 0.15916494],\n",
       "       [0.78627424, 0.87107214, 0.83101998],\n",
       "       [0.4969982 , 0.08944458, 0.74877767]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3,3).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000003?line=0'>1</a>\u001b[0m word\u001b[39m=\u001b[39mWordAttn(\u001b[39m200\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000003?line=2'>3</a>\u001b[0m word(torch\u001b[39m.\u001b[39;49mrand(\u001b[39m200\u001b[39;49m,\u001b[39m200\u001b[39;49m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Thesis\\Final_Presentation\\han\\han.py:81\u001b[0m, in \u001b[0;36mWordAttn.forward\u001b[1;34m(self, ip)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Thesis/Final_Presentation/han/han.py?line=77'>78</a>\u001b[0m output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(output, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='file:///d%3A/Thesis/Final_Presentation/han/han.py?line=78'>79</a>\u001b[0m \u001b[39m# [batch_size * num_sentences, sentence_length]\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/Thesis/Final_Presentation/han/han.py?line=80'>81</a>\u001b[0m attn_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49msoftmax(output, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='file:///d%3A/Thesis/Final_Presentation/han/han.py?line=81'>82</a>\u001b[0m \u001b[39m# [batch_size * num_sentences , sentence_length]\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Thesis/Final_Presentation/han/han.py?line=83'>84</a>\u001b[0m sent_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melement_wise_multiply(ip, attn_weights)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1680\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=1677'>1678</a>\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=1678'>1679</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=1679'>1680</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=1680'>1681</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=1681'>1682</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "word=WordAttn(200,'cpu')\n",
    "\n",
    "word(torch.rand(200,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"D:\\Thesis\\rerun\\wor2vec\\fold_0\\vocab_200.json\"\n",
    "with open(path,'r') as f:\n",
    "    wdv=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wdv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wdv['delhi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000007?line=3'>4</a>\u001b[0m embedding_vector \u001b[39m=\u001b[39m i\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000007?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m embedding_vector \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000007?line=5'>6</a>\u001b[0m     \u001b[39m# words not found in embedding index will be all-zeros.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000007?line=6'>7</a>\u001b[0m     embedding_matrix[i] \u001b[39m=\u001b[39m embedding_vector\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000007?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000007?line=8'>9</a>\u001b[0m     absent_words \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embed_size))\n",
    "absent_words = 0\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        absent_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)), '% of total words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.data prepartion \n",
    "2.model input\n",
    "3.doc embedding \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=3\n",
    "x=torch.rand(3,3)\n",
    "m=nn.Linear(in_features=input_dim,out_features=input_dim,bias=True)\n",
    "out=m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=nn.Tanh()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2104, -0.5039, -0.3376],\n",
       "        [-0.3498, -0.6957, -0.2947],\n",
       "        [ 0.2009, -0.3575, -0.1813]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=nn.Parameter(torch.Tensor(input_dim,1))\n",
    "weights=param.data.normal_(mean=0.0,std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "out =torch.matmul(out,param)\n",
    "out=torch.squeeze(out,dim=-1)\n",
    "att_w=F.softmax(out,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0121, 0.0147, 0.0070], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got 1, 1x1,3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000020?line=2'>3</a>\u001b[0m w\u001b[39m=\u001b[39mw\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000020?line=3'>4</a>\u001b[0m s\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msqueeze(s,dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000020?line=4'>5</a>\u001b[0m sent_e\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mmatmul(w,s)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000020?line=5'>6</a>\u001b[0m sent_em\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mcat((sent_em,sent_e),dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, got 1, 1x1,3"
     ]
    }
   ],
   "source": [
    "sent_em=torch.Tensor([])\n",
    "for s,w in zip(x,att_w):\n",
    "    w=w.view(1,-1)\n",
    "    s=torch.squeeze(s,dim=0)\n",
    "    sent_e=torch.matmul(w,s)\n",
    "    sent_em=torch.cat((sent_em,sent_e),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru=nn.GRU(input_size=input_dim,hidden_size=2,bidirectional=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000024?line=0'>1</a>\u001b[0m gru(x[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:833\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=830'>831</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=831'>832</a>\u001b[0m     batch_sizes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=832'>833</a>\u001b[0m     max_batch_size \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39melse\u001b[39;00m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=833'>834</a>\u001b[0m     sorted_indices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=834'>835</a>\u001b[0m     unsorted_indices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "gru(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=nn.Embedding(num_embeddings =1,embedding_dim=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_dict=[torch.Tensor(v) for k,v in wdv.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0696,  1.5705, -1.0371, -1.7758,  0.6169, -2.1731, -1.1762,  3.5082,\n",
       "         4.0245,  1.0452,  0.1777, -0.8022, -0.5311,  4.1145,  1.9032, -2.9305,\n",
       "         0.5490, -2.4362,  0.3503,  1.2581, -1.7697, -0.2456, -1.9041,  3.7110,\n",
       "         2.1213,  0.3331, -1.0566,  1.8388, -0.9516,  0.5425,  3.0840, -0.4972,\n",
       "        -1.7088,  1.2916, -4.3547, -0.3601,  1.8823, -1.0470, -1.5548, -1.7009,\n",
       "         3.7583,  0.4760,  1.8543,  0.1802, -1.4188, -1.2846,  4.9666,  0.0538,\n",
       "        -0.9291, -5.1471, -0.4209, -0.9943, -1.9112,  0.8155, -0.6347,  0.5952,\n",
       "         0.8306,  2.1269, -0.3240,  0.7065,  2.8146, -0.3707, -0.3281,  0.6793,\n",
       "         2.4985, -0.7090,  2.2290,  1.4793,  2.1250,  0.2532, -0.2294,  1.9990,\n",
       "         1.6981,  0.4208, -0.1206,  1.1749, -1.8316, -0.9280,  3.0375,  1.5805,\n",
       "        -1.9440,  0.3508, -2.0383,  0.0799, -2.9112,  1.3426, -1.6303,  2.0359,\n",
       "         5.4185, -2.0565, -0.4034,  2.6499,  4.0693, -2.4294,  0.7357,  3.8377,\n",
       "        -3.6958, -1.7261,  0.6617, -1.5109, -0.6758, -1.5135, -1.5987, -0.2191,\n",
       "         0.8194,  1.8419, -1.4048, -2.2597,  1.4815,  1.2056, -0.3686, -0.5429,\n",
       "         0.9840, -0.5002, -1.5080, -0.4296,  0.5482,  1.1664, -2.1288,  1.1124,\n",
       "         2.0707, -3.2789,  0.4501, -0.3267,  0.3910,  0.6522,  2.8692,  1.7499,\n",
       "         0.3037, -0.5001,  2.9149, -2.0571, -2.5471, -1.7758,  0.4482,  1.8948,\n",
       "        -1.5276,  1.2453,  0.8422,  0.7388,  2.2082, -1.4155, -0.6251,  0.1809,\n",
       "         0.9541, -0.4715, -0.9887,  0.6432, -3.5826, -1.4821, -0.0559, -3.7383,\n",
       "         2.9631,  1.1544, -0.7508, -0.7823,  0.6029,  1.8783,  0.1256,  1.8320,\n",
       "        -0.0657, -1.1766, -0.6287,  0.6192, -0.2593,  2.2714, -4.6317, -0.6118,\n",
       "         0.0635, -0.4300,  2.4028, -2.3054,  0.0852, -0.5640,  0.9324,  3.5901,\n",
       "         2.1467,  0.1825,  0.6343,  1.2690,  1.3793,  0.1038,  1.1812,  1.6405,\n",
       "        -0.6431, -1.5086, -0.1390,  2.2736,  3.1537, -0.0133,  1.1479,  2.0688,\n",
       "        -1.0401,  1.0942, -0.7750,  0.9422, -2.8860, -1.2897,  0.1286,  0.1529])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 27'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000031?line=0'>1</a>\u001b[0m x[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict_values' object is not subscriptable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000026?line=0'>1</a>\u001b[0m emb(my_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/sparse.py?line=156'>157</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/sparse.py?line=157'>158</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/sparse.py?line=158'>159</a>\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/sparse.py?line=159'>160</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2044\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2037'>2038</a>\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2038'>2039</a>\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2039'>2040</a>\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2040'>2041</a>\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2041'>2042</a>\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2042'>2043</a>\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/functional.py?line=2043'>2044</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "emb(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=nn.Embedding(num_embeddings =len(my_dict),embedding_dim=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=r\"D:\\Thesis\\rerun\\wor2vec\\fold_0\\word2vec_200.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000031?line=0'>1</a>\u001b[0m \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(filepath_or_buffer\u001b[39m=\u001b[39;49mp, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m, quoting\u001b[39m=\u001b[39;49mcsv\u001b[39m.\u001b[39;49mQUOTE_NONE)\u001b[39m.\u001b[39mvalues[:, \u001b[39m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1231'>1232</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1233'>1234</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1234'>1235</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1235'>1236</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1236'>1237</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=71'>72</a>\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=73'>74</a>\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=78'>79</a>\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:749\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "dict = pd.read_csv(filepath_or_buffer=p, header=None, sep=\" \", quoting=csv.QUOTE_NONE).values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru=nn.GRU(input_size=200,hidden_size=3,bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.6118e-01, -3.0997e-02,  8.4912e-03, -2.6226e-06,  6.4699e-01,\n",
       "            0.0000e+00]]], grad_fn=<CatBackward0>),\n",
       " tensor([[[ 1.6118e-01, -3.0997e-02,  8.4912e-03]],\n",
       " \n",
       "         [[-2.6226e-06,  6.4699e-01,  0.0000e+00]]], grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.Tensor(wdv['delhi']).reshape(1,1,len(wdv['delhi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=-1*torch.rand(1,1,3 ) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 3, got 200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Final_Presentation\\check.ipynb Cell 37'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Final_Presentation/check.ipynb#ch0000036?line=0'>1</a>\u001b[0m gru(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:847\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=841'>842</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=842'>843</a>\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=843'>844</a>\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=844'>845</a>\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=846'>847</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=847'>848</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=848'>849</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=849'>850</a>\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:229\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=227'>228</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=228'>229</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=229'>230</a>\u001b[0m     expected_hidden_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=231'>232</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=200'>201</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=201'>202</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=202'>203</a>\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=203'>204</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=204'>205</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=205'>206</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/ASUS/anaconda3/lib/site-packages/torch/nn/modules/rnn.py?line=206'>207</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 3, got 200"
     ]
    }
   ],
   "source": [
    "gru(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(1,3)\n",
    "y=torch.rand(1,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.stack([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0333, 0.5683, 0.9217]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.Tensor(wdv['delhi']).reshape(1,1,len(wdv['delhi']))\n",
    "y=torch.Tensor(wdv['high']).reshape(1,1,len(wdv['high']))\n",
    "out=torch.cat((x,y),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 200])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import json\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEncoder(nn.Module):\n",
    "    def __init__(self,args) -> None:\n",
    "        super(WordEncoder,self).__init__()\n",
    "        self.input_size = args.input_dim\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.gru_layer=nn.GRU(input_size=self.input_size,\n",
    "                              hidden_size=self.hidden_dim,\n",
    "                              bidirectional=True)\n",
    "\n",
    "    def forward(self,inp):\n",
    "        output = self.gru_layer(inp)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class argParser():\n",
    "    def __init__(self,path):\n",
    "        self.args=self.__arg_parser(path)\n",
    "        self.input_dim=self.args['INPUT_SIZE']\n",
    "        self.hidden_dim=self.args['HIDDEN_SIZE']\n",
    "\n",
    "    def __arg_parser(self,path):\n",
    "        with open(path,'r') as f:\n",
    "            args=json.load(f)\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_arg=argParser(r'D:\\Thesis\\Final_Presentation\\han\\args.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = WordEncoder(my_arg)\n",
    "ip=wd.forward(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 200])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2805e+00, -1.8922e+00, -3.9934e-01, -2.4294e+00, -7.4389e-01,\n",
       "          -9.1161e-01, -8.1602e-01, -8.3729e-01, -1.0362e+00, -1.0965e-01],\n",
       "         [-4.0063e-01, -2.1795e-01, -2.3573e-01,  1.6610e+00, -4.6581e-01,\n",
       "          -1.5485e+00,  1.6522e-01,  5.3731e-01,  6.2826e-01,  8.6019e-01],\n",
       "         [ 1.7553e+00, -1.4370e+00, -2.4996e-01,  6.3378e-01, -4.5832e-02,\n",
       "           4.5836e-01, -1.6988e+00,  8.9590e-01, -2.3443e-01, -4.7332e-01]],\n",
       "\n",
       "        [[-1.9301e-01,  1.3873e+00,  9.5708e-01, -5.2277e-02, -9.5447e-01,\n",
       "           7.0795e-01, -6.2272e-01, -9.7577e-01,  5.3204e-01,  1.4106e+00],\n",
       "         [-7.6347e-01, -2.1477e-01, -1.6375e+00,  8.2077e-01,  8.6696e-01,\n",
       "           1.3776e+00, -3.8738e-01,  4.0789e-01, -1.0872e+00,  6.5991e-01],\n",
       "         [-9.9332e-02,  4.4825e-01,  2.7667e-01, -1.6359e+00,  4.6708e-01,\n",
       "           1.3459e+00, -7.6880e-02,  1.5936e+00,  1.4007e+00,  4.8770e-01]],\n",
       "\n",
       "        [[ 4.2152e-01, -1.3654e+00, -1.4335e-01,  2.7557e-03,  1.8210e-02,\n",
       "           3.5178e-02,  2.4848e+00, -1.5466e+00,  3.3881e-02, -9.5414e-01],\n",
       "         [ 1.1071e+00, -7.9888e-01, -9.1393e-01,  4.7968e-01, -6.4451e-03,\n",
       "           7.3005e-01,  5.4760e-01, -2.2236e+00,  1.8964e-01, -1.0278e+00],\n",
       "         [ 1.1709e+00,  1.3956e-01,  6.2009e-01,  1.6394e+00,  5.6138e-02,\n",
       "          -1.2742e+00,  1.6880e+00,  3.3674e-01, -9.0408e-02,  5.8949e-01]],\n",
       "\n",
       "        [[-7.8106e-01,  1.4299e+00, -7.6444e-01, -7.4271e-01, -1.1143e+00,\n",
       "          -8.4701e-01,  1.2445e+00,  3.4211e-01,  1.0208e+00, -1.9186e+00],\n",
       "         [ 1.5067e+00, -3.0128e-01,  1.2389e+00,  2.3231e-01,  6.2268e-01,\n",
       "          -5.1239e-02,  8.6702e-01, -2.3423e+00, -9.1106e-01,  1.5133e-01],\n",
       "         [-2.8414e-01,  1.3114e+00, -2.1232e-01, -9.9696e-01, -8.6276e-01,\n",
       "          -3.9138e-01, -1.1499e+00,  4.4356e-01, -8.2231e-01,  1.2211e+00]],\n",
       "\n",
       "        [[-1.2898e-01, -5.4405e-01,  1.1962e+00, -1.1948e+00,  5.1005e-01,\n",
       "          -3.2217e-01, -8.0783e-01, -5.7819e-02,  1.2072e-01,  6.8738e-01],\n",
       "         [ 4.2921e-01, -4.9742e-01, -1.5802e+00,  7.3551e-01,  1.8234e+00,\n",
       "           1.1726e+00, -9.9126e-01, -7.4114e-01, -8.1108e-01, -1.5515e+00],\n",
       "         [ 1.3340e-01, -1.0925e+00,  6.3700e-01, -3.6658e-01,  7.4124e-01,\n",
       "           1.6726e-01, -3.9033e-01,  2.5663e-01,  2.0141e-03,  3.9641e-01]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(5,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"D:\\Thesis\\rerun\\wor2vec\\fold_0\\vocab_200.json\"\n",
    "with open(path,'r') as f:\n",
    "    wdv=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\facts\\1440.txt', 'r',encoding=\"utf8\") as f:\n",
    "    context=nltk.tokenize.sent_tokenize(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=word_tokenize(context[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0unsupported operation: the input tensors cannot refer to any of the output memory locations. Found overlap in input tensor 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Legal_AI\\script\\legal.1.1\\check.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000055?line=2'>3</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000055?line=3'>4</a>\u001b[0m     torch\u001b[39m.\u001b[39mcat((sen,torch\u001b[39m.\u001b[39mTensor(wdv[v]\u001b[39m.\u001b[39mlower())),out\u001b[39m=\u001b[39msen)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000055?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Delhi'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Legal_AI\\script\\legal.1.1\\check.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000055?line=3'>4</a>\u001b[0m     torch\u001b[39m.\u001b[39mcat((sen,torch\u001b[39m.\u001b[39mTensor(wdv[v]\u001b[39m.\u001b[39mlower())),out\u001b[39m=\u001b[39msen)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000055?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000055?line=5'>6</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mcat((sen,torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m200\u001b[39;49m)),dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,out\u001b[39m=\u001b[39;49msen)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0unsupported operation: the input tensors cannot refer to any of the output memory locations. Found overlap in input tensor 0"
     ]
    }
   ],
   "source": [
    "sen=torch.Tensor([])\n",
    "for v in vec:\n",
    "    try:\n",
    "        torch.cat((sen,torch.Tensor(wdv[v].lower())),out=sen)\n",
    "    except:\n",
    "        torch.cat((sen,torch.zeros(200)),dim=0,out=sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=torch.empty(200)\n",
    "sen=torch.stack([sen,torch.Tensor(wdv['delhi'])],dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0696,  1.5705, -1.0371, -1.7758,  0.6169, -2.1731, -1.1762,  3.5082,\n",
       "         4.0245,  1.0452,  0.1777, -0.8022, -0.5311,  4.1145,  1.9032, -2.9305,\n",
       "         0.5490, -2.4362,  0.3503,  1.2581, -1.7697, -0.2456, -1.9041,  3.7110,\n",
       "         2.1213,  0.3331, -1.0566,  1.8388, -0.9516,  0.5425,  3.0840, -0.4972,\n",
       "        -1.7088,  1.2916, -4.3547, -0.3601,  1.8823, -1.0470, -1.5548, -1.7009,\n",
       "         3.7583,  0.4760,  1.8543,  0.1802, -1.4188, -1.2846,  4.9666,  0.0538,\n",
       "        -0.9291, -5.1471, -0.4209, -0.9943, -1.9112,  0.8155, -0.6347,  0.5952,\n",
       "         0.8306,  2.1269, -0.3240,  0.7065,  2.8146, -0.3707, -0.3281,  0.6793,\n",
       "         2.4985, -0.7090,  2.2290,  1.4793,  2.1250,  0.2532, -0.2294,  1.9990,\n",
       "         1.6981,  0.4208, -0.1206,  1.1749, -1.8316, -0.9280,  3.0375,  1.5805,\n",
       "        -1.9440,  0.3508, -2.0383,  0.0799, -2.9112,  1.3426, -1.6303,  2.0359,\n",
       "         5.4185, -2.0565, -0.4034,  2.6499,  4.0693, -2.4294,  0.7357,  3.8377,\n",
       "        -3.6958, -1.7261,  0.6617, -1.5109, -0.6758, -1.5135, -1.5987, -0.2191,\n",
       "         0.8194,  1.8419, -1.4048, -2.2597,  1.4815,  1.2056, -0.3686, -0.5429,\n",
       "         0.9840, -0.5002, -1.5080, -0.4296,  0.5482,  1.1664, -2.1288,  1.1124,\n",
       "         2.0707, -3.2789,  0.4501, -0.3267,  0.3910,  0.6522,  2.8692,  1.7499,\n",
       "         0.3037, -0.5001,  2.9149, -2.0571, -2.5471, -1.7758,  0.4482,  1.8948,\n",
       "        -1.5276,  1.2453,  0.8422,  0.7388,  2.2082, -1.4155, -0.6251,  0.1809,\n",
       "         0.9541, -0.4715, -0.9887,  0.6432, -3.5826, -1.4821, -0.0559, -3.7383,\n",
       "         2.9631,  1.1544, -0.7508, -0.7823,  0.6029,  1.8783,  0.1256,  1.8320,\n",
       "        -0.0657, -1.1766, -0.6287,  0.6192, -0.2593,  2.2714, -4.6317, -0.6118,\n",
       "         0.0635, -0.4300,  2.4028, -2.3054,  0.0852, -0.5640,  0.9324,  3.5901,\n",
       "         2.1467,  0.1825,  0.6343,  1.2690,  1.3793,  0.1038,  1.1812,  1.6405,\n",
       "        -0.6431, -1.5086, -0.1390,  2.2736,  3.1537, -0.0133,  1.1479,  2.0688,\n",
       "        -1.0401,  1.0942, -0.7750,  0.9422, -2.8860, -1.2897,  0.1286,  0.1529])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "inpu = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(inpu, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1582,  0.6373, -0.4620, -1.9412, -0.0884,  0.5555, -1.4863,\n",
       "          -2.7538,  0.4418, -1.2150],\n",
       "         [ 1.4238,  0.1332, -0.1600,  0.2254, -0.6721, -0.8195, -1.8595,\n",
       "          -0.3239, -0.3056, -0.5261],\n",
       "         [-0.3668,  0.1759,  1.1484,  0.7886, -1.0071, -1.9894,  1.8648,\n",
       "           0.2261,  0.3849,  2.3369]],\n",
       "\n",
       "        [[ 1.1326,  0.5817,  0.4349,  0.0872,  0.6344,  0.2148, -0.2052,\n",
       "           0.2996, -0.1444, -0.6517],\n",
       "         [ 1.0568,  0.1634,  1.1131,  0.6351, -1.3747,  0.0624, -1.3077,\n",
       "          -0.1971,  0.2223,  1.3656],\n",
       "         [ 1.7791, -0.0095, -0.5123,  1.2232,  2.0284,  1.1009,  0.3887,\n",
       "          -2.3344, -0.1136, -0.1483]],\n",
       "\n",
       "        [[-0.2504, -0.6894,  0.7301, -1.6632,  0.0198, -1.4827, -1.4362,\n",
       "          -0.2488,  0.6488, -0.0826],\n",
       "         [-0.3480,  1.0506, -0.7724,  1.4312, -1.2519,  0.3807, -0.6795,\n",
       "           0.0465, -0.3087,  1.3418],\n",
       "         [ 0.6106, -0.7371, -0.3779,  1.4991, -0.4810, -0.7521,  0.5732,\n",
       "          -1.0979,  1.2449,  0.9038]],\n",
       "\n",
       "        [[ 1.0777, -0.7482,  0.7768, -1.2668, -3.3652, -0.1132, -0.9667,\n",
       "           0.7136, -0.8925,  0.2665],\n",
       "         [ 1.2313,  0.3134, -0.5693, -0.1287,  1.4917,  0.1923,  0.1367,\n",
       "           0.6919, -2.6220, -1.7987],\n",
       "         [ 0.8304,  0.4456,  0.3275,  0.9835,  1.5248,  0.2667, -0.6061,\n",
       "           1.4584, -1.8315,  0.9849]],\n",
       "\n",
       "        [[-0.1990,  0.5297, -0.2789,  0.5127, -2.4749, -0.1809,  1.2249,\n",
       "           0.5616,  1.6294, -1.1515],\n",
       "         [-0.6873, -0.6954,  0.8654,  0.8136, -1.0260,  0.7815,  0.5880,\n",
       "          -0.1065,  2.1173, -0.2027],\n",
       "         [-0.6305,  1.0269, -1.9073, -1.2789,  0.6981,  1.1548, -0.3634,\n",
       "           0.6529,  1.5376,  0.1915]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=rnn(inpu, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"D:\\Thesis\\rerun\\wor2vec\\fold_0\\vocab_200.json\"\n",
    "with open(path,'r') as f:\n",
    "    wdv=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.Tensor(wdv['delhi']).reshape(1,1,len(wdv['delhi']))\n",
    "y=torch.Tensor(wdv['high']).reshape(1,1,len(wdv['high']))\n",
    "out=torch.stack((x,y),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1, 200])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\Thesis\\Legal_AI\\script\\legal.1.1\\IPC_data\\ipc_case_offences.json\",'r') as f:\n",
    "    target=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6012"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output='sen'\n",
    "if not os.path.isdir(output):\n",
    "    os.mkdir(output)\n",
    "for k,v in target.items():\n",
    "    shutil.copy(os.path.join(r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\sentences', f\"{k}.txt\"),output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\facts\\1440.txt','r') as f:\n",
    "    content= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = content.split()\n",
    "words = list(filter(lambda x: x != \"\", words))\n",
    "length = len(words)\n",
    "words = [word.strip(\"./-?!\") for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb=[]\n",
    "for w in words:\n",
    "    sent_emb.append(wdv.get(w,torch.zeros(200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 8 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Thesis\\Legal_AI\\script\\legal.1.1\\check.ipynb Cell 74'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Thesis/Legal_AI/script/legal.1.1/check.ipynb#ch0000079?line=0'>1</a>\u001b[0m sent_emb\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mstack(sent_emb)\n",
      "\u001b[1;31mTypeError\u001b[0m: expected Tensor as element 8 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "sent_emb=torch.stack(sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=wdv.get('Delhi',torch.zeros(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=[torch.zeros(10) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "se=[]\n",
    "for i in range(10):\n",
    "    se.append(torch.zeros(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(se[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(se,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.load(r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\save\\28102.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_p=r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\save'\n",
    "test_p=r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\IPC_data\\fold_0\\test'\n",
    "train_p=r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\IPC_data\\fold_0\\train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list=os.listdir(test_p)\n",
    "test_list=[k.split('.')[0] for k in test_list]\n",
    "train_list=os.listdir(train_p)\n",
    "train_list=[k.split('.')[0] for k in train_list]\n",
    "original_list=os.listdir(save_p)\n",
    "original_list.remove(\"gen_embeds.log\")\n",
    "original_list=[k.split('.')[0] for k in original_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[k for k in train_list if k in original_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3901"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "output='Han_vect'\n",
    "\n",
    "if not os.path.isdir(output):\n",
    "    os.mkdir(output)\n",
    "\n",
    "if not os.path.isdir(os.path.join(output,'test')):\n",
    "    os.mkdir(os.path.join(output,'test'))\n",
    "\n",
    "if not os.path.isdir(os.path.join(output,'train')):\n",
    "    os.mkdir(os.path.join(output,'train'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in test_list:\n",
    "    shutil.copy(os.path.join(r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\save', f\"{k}.pt\"),os.path.join(output,'test'))\n",
    "\n",
    "for k in train_list:\n",
    "    shutil.copy(os.path.join(r'D:\\Thesis\\Legal_AI\\script\\legal.1.1\\save', f\"{k}.pt\"),os.path.join(output,'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "380030d1298d5a27518acca789ff38fe82bbf2e68b73263de6a6bf23efb7704c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
